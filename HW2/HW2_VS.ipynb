{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "---\n",
    "title: \"FINM 250 HW2\n",
    "author: \"Victoria Shi\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml\n",
    "jupyter: python3\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "86a0b401",
   "metadata": {},
   "source": [
    "## 2 Analyzing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. For the series in the “hedge fund series” tab, report the following summary statistics:\n",
    "(a) mean\n",
    "(b) volatility\n",
    "(c) Sharpe ratio\n",
    "Annualize these statistics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "import seaborn as sns\n",
    "from janitor import clean_names, remove_empty\n",
    "sns.set_theme(style='white', palette='cubehelix', font_scale = 0.8, rc={'figure.figsize': (8, 6)})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.706660Z",
     "start_time": "2023-07-10T07:11:03.415972Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "   HFRIFWI Index  MLEIFCTR Index  MLEIFCTX Index  HDG US Equity  QAI US Equity\n0          -0.03           -0.03           -0.03          -0.03          -0.01\n1          -0.04           -0.03           -0.03          -0.03          -0.02\n2           0.03            0.04            0.04           0.05           0.03\n3          -0.01           -0.01           -0.01          -0.03          -0.01\n4          -0.00            0.00            0.00           0.01           0.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HFRIFWI Index</th>\n      <th>MLEIFCTR Index</th>\n      <th>MLEIFCTX Index</th>\n      <th>HDG US Equity</th>\n      <th>QAI US Equity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.03</td>\n      <td>-0.03</td>\n      <td>-0.03</td>\n      <td>-0.03</td>\n      <td>-0.01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.04</td>\n      <td>-0.03</td>\n      <td>-0.03</td>\n      <td>-0.03</td>\n      <td>-0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.03</td>\n      <td>0.04</td>\n      <td>0.04</td>\n      <td>0.05</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.01</td>\n      <td>-0.01</td>\n      <td>-0.01</td>\n      <td>-0.03</td>\n      <td>-0.01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hedge_df = (pd.read_excel('/Users/victoriashi/Desktop/Quant-Fin-Algo-Trading/HW2/proshares_analysis_data.xlsx', sheet_name='hedge_fund_series', parse_dates=True, index_col=0).pipe(remove_empty)\n",
    ")\n",
    "hedge_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.776903Z",
     "start_time": "2023-07-10T07:11:03.419795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(RangeIndex(start=0, stop=142, step=1),\n Index(['HFRIFWI Index', 'MLEIFCTR Index', 'MLEIFCTX Index', 'HDG US Equity',\n        'QAI US Equity'],\n       dtype='object'),\n HFRIFWI Index    0.04\n MLEIFCTR Index   0.03\n MLEIFCTX Index   0.03\n HDG US Equity    0.02\n QAI US Equity    0.02\n dtype: float64)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hedge_df.index, hedge_df.columns, hedge_df.mean() * 12"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.777195Z",
     "start_time": "2023-07-10T07:11:03.440575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                Mean  Vol  Sharpe\nHFRIFWI Index   0.04 0.06    0.69\nMLEIFCTR Index  0.03 0.06    0.54\nMLEIFCTX Index  0.03 0.06    0.51\nHDG US Equity   0.02 0.06    0.33\nQAI US Equity   0.02 0.05    0.34",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Vol</th>\n      <th>Sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>HFRIFWI Index</th>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTR Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTX Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>HDG US Equity</th>\n      <td>0.02</td>\n      <td>0.06</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>QAI US Equity</th>\n      <td>0.02</td>\n      <td>0.05</td>\n      <td>0.34</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean, volatility and Sharpe ratio\n",
    "hedge_df_summary = pd.DataFrame(index=hedge_df.columns)\n",
    "hedge_df_summary['Mean'] = hedge_df.mean() * 12\n",
    "hedge_df_summary['Vol'] = hedge_df.std() * np.sqrt(12)\n",
    "hedge_df_summary['Sharpe'] = (hedge_df.mean() / hedge_df.std()) * np.sqrt(12)\n",
    "hedge_df_summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.777301Z",
     "start_time": "2023-07-10T07:11:03.444448Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. For the series in the “hedge fund series” tab, calculate the following statistics related to tail-drawdownrisk.\n",
    "(a) Skewness\n",
    "(b) Kurtosis\n",
    "(c) the fifth quantile of historic returns, which is also known as the Value-at-Risk (VaR)\n",
    "(d) the mean of the returns at or below the fifth quantile, which is also known as the Conditional\n",
    "Value-at-Risk (CVaR)\n",
    "(e) Maximum drawdown - include the dates of the max/min/recovery within the max drawdown period.\n",
    "There is no need to annualize any of these statistics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "                Mean  Vol  Sharpe  Skewness  Kurtosis   VaR  CVaR\nHFRIFWI Index   0.04 0.06    0.69     -0.98      5.96 -0.03 -0.04\nMLEIFCTR Index  0.03 0.06    0.54     -0.24      1.69 -0.03 -0.04\nMLEIFCTX Index  0.03 0.06    0.51     -0.23      1.66 -0.03 -0.04\nHDG US Equity   0.02 0.06    0.33     -0.23      1.80 -0.03 -0.04\nQAI US Equity   0.02 0.05    0.34     -0.46      1.83 -0.02 -0.03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Vol</th>\n      <th>Sharpe</th>\n      <th>Skewness</th>\n      <th>Kurtosis</th>\n      <th>VaR</th>\n      <th>CVaR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>HFRIFWI Index</th>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.69</td>\n      <td>-0.98</td>\n      <td>5.96</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTR Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.54</td>\n      <td>-0.24</td>\n      <td>1.69</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTX Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.51</td>\n      <td>-0.23</td>\n      <td>1.66</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>HDG US Equity</th>\n      <td>0.02</td>\n      <td>0.06</td>\n      <td>0.33</td>\n      <td>-0.23</td>\n      <td>1.80</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>QAI US Equity</th>\n      <td>0.02</td>\n      <td>0.05</td>\n      <td>0.34</td>\n      <td>-0.46</td>\n      <td>1.83</td>\n      <td>-0.02</td>\n      <td>-0.03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) b) c)\n",
    "hedge_df_summary['Skewness'] = hedge_df.skew()\n",
    "hedge_df_summary['Kurtosis'] = hedge_df.kurtosis()\n",
    "hedge_df_summary['VaR'] = hedge_df.quantile(0.05) # 'VaR' is also the 5th quantile\n",
    "hedge_df_summary['CVaR'] = hedge_df[hedge_df <= hedge_df.quantile(0.05)].mean() # 'CVaR' is also the mean of the returns at or below the 5th quantile\n",
    "\n",
    "hedge_df_summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.779750Z",
     "start_time": "2023-07-10T07:11:03.450407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hedge_df[\"QAI US Equity\"].index[2]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.779881Z",
     "start_time": "2023-07-10T07:11:03.455944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                Mean  Vol  Sharpe  Skewness  Kurtosis   VaR  CVaR\nHFRIFWI Index   0.04 0.06    0.69     -0.98      5.96 -0.03 -0.04\nMLEIFCTR Index  0.03 0.06    0.54     -0.24      1.69 -0.03 -0.04\nMLEIFCTX Index  0.03 0.06    0.51     -0.23      1.66 -0.03 -0.04\nHDG US Equity   0.02 0.06    0.33     -0.23      1.80 -0.03 -0.04\nQAI US Equity   0.02 0.05    0.34     -0.46      1.83 -0.02 -0.03",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean</th>\n      <th>Vol</th>\n      <th>Sharpe</th>\n      <th>Skewness</th>\n      <th>Kurtosis</th>\n      <th>VaR</th>\n      <th>CVaR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>HFRIFWI Index</th>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>0.69</td>\n      <td>-0.98</td>\n      <td>5.96</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTR Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.54</td>\n      <td>-0.24</td>\n      <td>1.69</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTX Index</th>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.51</td>\n      <td>-0.23</td>\n      <td>1.66</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>HDG US Equity</th>\n      <td>0.02</td>\n      <td>0.06</td>\n      <td>0.33</td>\n      <td>-0.23</td>\n      <td>1.80</td>\n      <td>-0.03</td>\n      <td>-0.04</td>\n    </tr>\n    <tr>\n      <th>QAI US Equity</th>\n      <td>0.02</td>\n      <td>0.05</td>\n      <td>0.34</td>\n      <td>-0.46</td>\n      <td>1.83</td>\n      <td>-0.02</td>\n      <td>-0.03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hedge_df_summary.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.779970Z",
     "start_time": "2023-07-10T07:11:03.458685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Calculate the maximum drawdown - also the dates of the max/min/recovery within the max drawdown period\n",
    "cum_returns = (1 + hedge_df).cumprod()\n",
    "rolling_max = cum_returns.cummax()\n",
    "drawdown = (cum_returns - rolling_max) / rolling_max\n",
    "max_drawdown = drawdown.min()\n",
    "end_date = drawdown.idxmin()\n",
    "summary = pd.DataFrame({'Max Drawdown': max_drawdown, 'Bottom': end_date})\n",
    "for col in drawdown:\n",
    "    summary.loc[col,'Peak'] = (rolling_max.loc[:end_date[col],col]).idxmax()\n",
    "    recovery = (drawdown.loc[end_date[col]:,col])\n",
    "    try:\n",
    "        summary.loc[col,'Recover'] = pd.to_datetime(recovery[recovery >= 0].index[0])\n",
    "    except:\n",
    "        summary.loc[col,'Recover'] = pd.to_datetime(None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.780088Z",
     "start_time": "2023-07-10T07:11:03.463966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                Max Drawdown  Bottom   Peak                       Recover\nHFRIFWI Index          -0.12     103 100.00 1970-01-01 00:00:00.000000108\nMLEIFCTR Index         -0.12     133 118.00                           NaT\nMLEIFCTX Index         -0.12     133 118.00                           NaT\nHDG US Equity          -0.14     133 118.00                           NaT\nQAI US Equity          -0.14     133 118.00                           NaT",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max Drawdown</th>\n      <th>Bottom</th>\n      <th>Peak</th>\n      <th>Recover</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>HFRIFWI Index</th>\n      <td>-0.12</td>\n      <td>103</td>\n      <td>100.00</td>\n      <td>1970-01-01 00:00:00.000000108</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTR Index</th>\n      <td>-0.12</td>\n      <td>133</td>\n      <td>118.00</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>MLEIFCTX Index</th>\n      <td>-0.12</td>\n      <td>133</td>\n      <td>118.00</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>HDG US Equity</th>\n      <td>-0.14</td>\n      <td>133</td>\n      <td>118.00</td>\n      <td>NaT</td>\n    </tr>\n    <tr>\n      <th>QAI US Equity</th>\n      <td>-0.14</td>\n      <td>133</td>\n      <td>118.00</td>\n      <td>NaT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.781752Z",
     "start_time": "2023-07-10T07:11:03.469895Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. For the series in the “hedge fund series” tab, run a regression of each against SPY (found in the\n",
    "“merrill factors” tab.) Include an intercept. Report the following regression-based statistics:\n",
    "(a) Market Beta\n",
    "(b) Treynor Ratio\n",
    "(c) Information ratio\n",
    "No need to annualize the market beta. The Treynor ratio is annualized by multiplying by the\n",
    "number of periods in a year. The Information ratio is annualized by multiplying by √12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(142, 5)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hedge_df.head()\n",
    "hedge_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.781856Z",
     "start_time": "2023-07-10T07:11:03.473603Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(142,)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPY = pd.read_excel('proshares_analysis_data.xlsx', sheet_name='merrill_factors', parse_dates=True, index_col=0).loc[:, 'SPY US Equity']\n",
    "SPY.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.781933Z",
     "start_time": "2023-07-10T07:11:03.476426Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [HFRIFWI Index, MLEIFCTR Index, MLEIFCTX Index, HDG US Equity, QAI US Equity, SPY US Equity]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HFRIFWI Index</th>\n      <th>MLEIFCTR Index</th>\n      <th>MLEIFCTX Index</th>\n      <th>HDG US Equity</th>\n      <th>QAI US Equity</th>\n      <th>SPY US Equity</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes  - hedge_df and SPY\n",
    "merged_df = pd.merge(hedge_df, SPY, how='inner', left_index=True, right_index=True)\n",
    "merged_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.788535Z",
     "start_time": "2023-07-10T07:11:03.498378Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Define the functions that we need\n",
    "def performanceMetrics(returns,annualization=1, quantile=.05):\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Mean'] = returns.mean() * annualization\n",
    "    metrics['Vol'] = returns.std() * np.sqrt(annualization)\n",
    "    metrics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annualization)\n",
    "\n",
    "    metrics['Min'] = returns.min()\n",
    "    metrics['Max'] = returns.max()\n",
    "    return metrics\n",
    "\n",
    "def drawdowns(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    rolling_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    end_date = drawdown.idxmin()\n",
    "    summary = pd.DataFrame({'Max Drawdown': max_drawdown, 'Bottom': end_date})\n",
    "    for col in drawdown:\n",
    "        summary.loc[col,'Peak'] = (rolling_max.loc[:end_date[col],col]).idxmax()\n",
    "        recovery = (drawdown.loc[end_date[col]:,col])\n",
    "        try:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(recovery[recovery >= 0].index[0])\n",
    "        except:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(None)\n",
    "    return summary\n",
    "\n",
    "def regression(returns, benchmark):\n",
    "    reg = LinearRegression().fit(benchmark.values.reshape(-1,1), returns)\n",
    "    return reg.coef_[0], reg.intercept_\n",
    "\n",
    "def regressionMetrics(returns, benchmark, annualization=1):\n",
    "    beta, alpha = regression(returns, benchmark)\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Market Beta'] = beta\n",
    "    metrics['Treynor Ratio'] = (returns.mean() - benchmark.mean()) / beta\n",
    "    metrics['Information Ratio'] = (returns.mean() - benchmark.mean()) / (returns.std() * np.sqrt(annualization))\n",
    "    return metrics\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.788588Z",
     "start_time": "2023-07-10T07:11:03.504058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Run the regression\n",
    "regression_df = pd.DataFrame(index=hedge_df.columns)\n",
    "regression_df['Market Beta'] = np.nan\n",
    "regression_df['Treynor Ratio'] = np.nan\n",
    "regression_df['Information Ratio'] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.788811Z",
     "start_time": "2023-07-10T07:11:03.507286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:03.788855Z",
     "start_time": "2023-07-10T07:11:03.509272Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69d107b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:04.372344Z",
     "start_time": "2023-07-10T07:11:03.512127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some useful packages and functions\n",
    "\n",
    "# Import the packages we need\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define the functions that we need\n",
    "\n",
    "#Mean, Volatality and Sharpe Ratio\n",
    "def performanceMetrics(returns,annualization=1, quantile=.05):\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Mean'] = returns.mean() * annualization\n",
    "    metrics['Vol'] = returns.std() * np.sqrt(annualization)\n",
    "    metrics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annualization)\n",
    "\n",
    "    metrics['Min'] = returns.min()\n",
    "    metrics['Max'] = returns.max()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "#VaR, CVaR, Max Drawdown\n",
    "def tailMetrics(returns, quantile=.05, relative=False, mdd=True):\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Skewness'] = returns.skew()\n",
    "    metrics['Kurtosis'] = returns.kurtosis()\n",
    "\n",
    "    VaR = returns.quantile(quantile)\n",
    "    CVaR = (returns[returns < returns.quantile(quantile)]).mean()\n",
    "\n",
    "    if relative:\n",
    "        VaR = (VaR - returns.mean())/returns.std()\n",
    "        CVaR = (CVaR - returns.mean())/returns.std()\n",
    "\n",
    "    metrics[f'VaR ({quantile})'] = VaR\n",
    "    metrics[f'CVaR ({quantile})'] = CVaR\n",
    "\n",
    "    if mdd:\n",
    "        mdd_stats = maximumDrawdown(returns)\n",
    "        metrics = metrics.join(mdd_stats)\n",
    "\n",
    "        if relative:\n",
    "            metrics['Max Drawdown'] = (metrics['Max Drawdown'] - returns.mean())/returns.std()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def maximumDrawdown(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    rolling_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns - rolling_max) / rolling_max\n",
    "\n",
    "    max_drawdown = drawdown.min()\n",
    "    end_date = drawdown.idxmin()\n",
    "    summary = pd.DataFrame({'Max Drawdown': max_drawdown, 'Bottom': end_date})\n",
    "\n",
    "    for col in drawdown:\n",
    "        summary.loc[col,'Peak'] = (rolling_max.loc[:end_date[col],col]).idxmax()\n",
    "        recovery = (drawdown.loc[end_date[col]:,col])\n",
    "        try:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(recovery[recovery >= 0].index[0])\n",
    "        except:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(None)\n",
    "\n",
    "        summary['Peak'] = pd.to_datetime(summary['Peak'])\n",
    "        try:\n",
    "            summary['Duration (to Recover)'] = (summary['Recover'] - summary['Peak'])\n",
    "        except:\n",
    "            summary['Duration (to Recover)'] = None\n",
    "            \n",
    "        summary = summary[['Max Drawdown','Peak','Bottom','Recover','Duration (to Recover)']]\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "#Run OLS\n",
    "def get_ols_metrics(regressors, targets, annualization=1, ignorenan=True):\n",
    "    # ensure regressors and targets are pandas dataframes, as expected\n",
    "    if not isinstance(regressors, pd.DataFrame):\n",
    "        regressors = regressors.to_frame()\n",
    "    if not isinstance(targets, pd.DataFrame):\n",
    "        targets = targets.to_frame()\n",
    "\n",
    "    # align the targets and regressors on the same dates\n",
    "    df_aligned = targets.join(regressors, how='inner', lsuffix='y ')\n",
    "    Y = df_aligned[targets.columns]\n",
    "    Xset = df_aligned[regressors.columns]\n",
    "\n",
    "    reg = pd.DataFrame(index=targets.columns)\n",
    "    for col in Y.columns:\n",
    "        y = Y[col]\n",
    "        \n",
    "        if ignorenan:\n",
    "            # ensure we use only non-NaN dates\n",
    "            alldata = Xset.join(y,lsuffix='X')\n",
    "            mask = alldata.notnull().all(axis=1)\n",
    "            y = y[mask]\n",
    "            X = Xset[mask]\n",
    "        else:\n",
    "            X = Xset\n",
    "\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        reg.loc[col, 'alpha'] = model.intercept_ * annualization\n",
    "        reg.loc[col, regressors.columns] = model.coef_\n",
    "        reg.loc[col, 'r-squared'] = model.score(X, y)\n",
    "\n",
    "        # sklearn does not return the residuals, so we need to build them\n",
    "        yfit = model.predict(X)\n",
    "        residuals = y - yfit\n",
    "\n",
    "        # Treynor Ratio is only defined for univariate regression\n",
    "        if Xset.shape[1] == 1:\n",
    "            reg.loc[col,'Treynor Ratio'] = (y.mean() / model.coef_) * annualization\n",
    "\n",
    "        \n",
    "        # if intercept =0, numerical roundoff will nonetheless show nonzero Info Ratio\n",
    "        num_roundoff = 1e-12\n",
    "        if np.abs(model.intercept_) < num_roundoff:\n",
    "            reg.loc[col, 'Info Ratio'] = None\n",
    "        else:\n",
    "            reg.loc[col, 'Info Ratio'] = (model.intercept_ / residuals.std()) * np.sqrt(annualization)\n",
    "\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "813eb711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T07:11:04.521480Z",
     "start_time": "2023-07-10T07:11:04.373152Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [47]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m desc \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproshares_analysis_data.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescriptions\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnnamed: 0\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSymbol\u001B[39m\u001B[38;5;124m'\u001B[39m})\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSymbol\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#Hedge Fund Data\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m hf \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mproshares_analysis_data.xlsx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhedge_fund_series\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_index\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#Merrill Lynch Factor Data\u001B[39;00m\n\u001B[1;32m     10\u001B[0m mf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproshares_analysis_data.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmerrill_factors\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    298\u001B[0m     allow_args \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    299\u001B[0m         p\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    300\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m old_sig\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m (p\u001B[38;5;241m.\u001B[39mPOSITIONAL_ONLY, p\u001B[38;5;241m.\u001B[39mPOSITIONAL_OR_KEYWORD)\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mdefault \u001B[38;5;129;01mis\u001B[39;00m p\u001B[38;5;241m.\u001B[39mempty\n\u001B[1;32m    303\u001B[0m     ]\n\u001B[1;32m    305\u001B[0m new_params \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    306\u001B[0m     p\u001B[38;5;241m.\u001B[39mreplace(kind\u001B[38;5;241m=\u001B[39mp\u001B[38;5;241m.\u001B[39mKEYWORD_ONLY)\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    308\u001B[0m         p\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m (p\u001B[38;5;241m.\u001B[39mPOSITIONAL_ONLY, p\u001B[38;5;241m.\u001B[39mPOSITIONAL_OR_KEYWORD)\n\u001B[1;32m    309\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m allow_args\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m p\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m old_sig\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[1;32m    313\u001B[0m ]\n\u001B[1;32m    314\u001B[0m new_params\u001B[38;5;241m.\u001B[39msort(key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m p: p\u001B[38;5;241m.\u001B[39mkind)\n\u001B[1;32m    315\u001B[0m new_sig \u001B[38;5;241m=\u001B[39m old_sig\u001B[38;5;241m.\u001B[39mreplace(parameters\u001B[38;5;241m=\u001B[39mnew_params)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:5503\u001B[0m, in \u001B[0;36mset_index\u001B[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001B[0m\n\u001B[1;32m   5454\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrename\u001B[39m(\n\u001B[1;32m   5455\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5456\u001B[0m     mapper: Renamer \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5464\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5465\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5466\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5467\u001B[0m \u001B[38;5;124;03m    Alter axes labels.\u001B[39;00m\n\u001B[1;32m   5468\u001B[0m \n\u001B[1;32m   5469\u001B[0m \u001B[38;5;124;03m    Function / dict values must be unique (1-to-1). Labels not contained in\u001B[39;00m\n\u001B[1;32m   5470\u001B[0m \u001B[38;5;124;03m    a dict / Series will be left as-is. Extra labels listed don't throw an\u001B[39;00m\n\u001B[1;32m   5471\u001B[0m \u001B[38;5;124;03m    error.\u001B[39;00m\n\u001B[1;32m   5472\u001B[0m \n\u001B[1;32m   5473\u001B[0m \u001B[38;5;124;03m    See the :ref:`user guide <basics.rename>` for more.\u001B[39;00m\n\u001B[1;32m   5474\u001B[0m \n\u001B[1;32m   5475\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   5476\u001B[0m \u001B[38;5;124;03m    ----------\u001B[39;00m\n\u001B[1;32m   5477\u001B[0m \u001B[38;5;124;03m    mapper : dict-like or function\u001B[39;00m\n\u001B[1;32m   5478\u001B[0m \u001B[38;5;124;03m        Dict-like or function transformations to apply to\u001B[39;00m\n\u001B[1;32m   5479\u001B[0m \u001B[38;5;124;03m        that axis' values. Use either ``mapper`` and ``axis`` to\u001B[39;00m\n\u001B[1;32m   5480\u001B[0m \u001B[38;5;124;03m        specify the axis to target with ``mapper``, or ``index`` and\u001B[39;00m\n\u001B[1;32m   5481\u001B[0m \u001B[38;5;124;03m        ``columns``.\u001B[39;00m\n\u001B[1;32m   5482\u001B[0m \u001B[38;5;124;03m    index : dict-like or function\u001B[39;00m\n\u001B[1;32m   5483\u001B[0m \u001B[38;5;124;03m        Alternative to specifying axis (``mapper, axis=0``\u001B[39;00m\n\u001B[1;32m   5484\u001B[0m \u001B[38;5;124;03m        is equivalent to ``index=mapper``).\u001B[39;00m\n\u001B[1;32m   5485\u001B[0m \u001B[38;5;124;03m    columns : dict-like or function\u001B[39;00m\n\u001B[1;32m   5486\u001B[0m \u001B[38;5;124;03m        Alternative to specifying axis (``mapper, axis=1``\u001B[39;00m\n\u001B[1;32m   5487\u001B[0m \u001B[38;5;124;03m        is equivalent to ``columns=mapper``).\u001B[39;00m\n\u001B[1;32m   5488\u001B[0m \u001B[38;5;124;03m    axis : {0 or 'index', 1 or 'columns'}, default 0\u001B[39;00m\n\u001B[1;32m   5489\u001B[0m \u001B[38;5;124;03m        Axis to target with ``mapper``. Can be either the axis name\u001B[39;00m\n\u001B[1;32m   5490\u001B[0m \u001B[38;5;124;03m        ('index', 'columns') or number (0, 1). The default is 'index'.\u001B[39;00m\n\u001B[1;32m   5491\u001B[0m \u001B[38;5;124;03m    copy : bool, default True\u001B[39;00m\n\u001B[1;32m   5492\u001B[0m \u001B[38;5;124;03m        Also copy underlying data.\u001B[39;00m\n\u001B[1;32m   5493\u001B[0m \u001B[38;5;124;03m    inplace : bool, default False\u001B[39;00m\n\u001B[1;32m   5494\u001B[0m \u001B[38;5;124;03m        Whether to modify the DataFrame rather than creating a new one.\u001B[39;00m\n\u001B[1;32m   5495\u001B[0m \u001B[38;5;124;03m        If True then value of copy is ignored.\u001B[39;00m\n\u001B[1;32m   5496\u001B[0m \u001B[38;5;124;03m    level : int or level name, default None\u001B[39;00m\n\u001B[1;32m   5497\u001B[0m \u001B[38;5;124;03m        In case of a MultiIndex, only rename labels in the specified\u001B[39;00m\n\u001B[1;32m   5498\u001B[0m \u001B[38;5;124;03m        level.\u001B[39;00m\n\u001B[1;32m   5499\u001B[0m \u001B[38;5;124;03m    errors : {'ignore', 'raise'}, default 'ignore'\u001B[39;00m\n\u001B[1;32m   5500\u001B[0m \u001B[38;5;124;03m        If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\u001B[39;00m\n\u001B[1;32m   5501\u001B[0m \u001B[38;5;124;03m        or `columns` contains labels that are not present in the Index\u001B[39;00m\n\u001B[1;32m   5502\u001B[0m \u001B[38;5;124;03m        being transformed.\u001B[39;00m\n\u001B[0;32m-> 5503\u001B[0m \u001B[38;5;124;03m        If 'ignore', existing keys will be renamed and extra keys will be\u001B[39;00m\n\u001B[1;32m   5504\u001B[0m \u001B[38;5;124;03m        ignored.\u001B[39;00m\n\u001B[1;32m   5505\u001B[0m \n\u001B[1;32m   5506\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   5507\u001B[0m \u001B[38;5;124;03m    -------\u001B[39;00m\n\u001B[1;32m   5508\u001B[0m \u001B[38;5;124;03m    DataFrame or None\u001B[39;00m\n\u001B[1;32m   5509\u001B[0m \u001B[38;5;124;03m        DataFrame with the renamed axis labels or None if ``inplace=True``.\u001B[39;00m\n\u001B[1;32m   5510\u001B[0m \n\u001B[1;32m   5511\u001B[0m \u001B[38;5;124;03m    Raises\u001B[39;00m\n\u001B[1;32m   5512\u001B[0m \u001B[38;5;124;03m    ------\u001B[39;00m\n\u001B[1;32m   5513\u001B[0m \u001B[38;5;124;03m    KeyError\u001B[39;00m\n\u001B[1;32m   5514\u001B[0m \u001B[38;5;124;03m        If any of the labels is not found in the selected axis and\u001B[39;00m\n\u001B[1;32m   5515\u001B[0m \u001B[38;5;124;03m        \"errors='raise'\".\u001B[39;00m\n\u001B[1;32m   5516\u001B[0m \n\u001B[1;32m   5517\u001B[0m \u001B[38;5;124;03m    See Also\u001B[39;00m\n\u001B[1;32m   5518\u001B[0m \u001B[38;5;124;03m    --------\u001B[39;00m\n\u001B[1;32m   5519\u001B[0m \u001B[38;5;124;03m    DataFrame.rename_axis : Set the name of the axis.\u001B[39;00m\n\u001B[1;32m   5520\u001B[0m \n\u001B[1;32m   5521\u001B[0m \u001B[38;5;124;03m    Examples\u001B[39;00m\n\u001B[1;32m   5522\u001B[0m \u001B[38;5;124;03m    --------\u001B[39;00m\n\u001B[1;32m   5523\u001B[0m \u001B[38;5;124;03m    ``DataFrame.rename`` supports two calling conventions\u001B[39;00m\n\u001B[1;32m   5524\u001B[0m \n\u001B[1;32m   5525\u001B[0m \u001B[38;5;124;03m    * ``(index=index_mapper, columns=columns_mapper, ...)``\u001B[39;00m\n\u001B[1;32m   5526\u001B[0m \u001B[38;5;124;03m    * ``(mapper, axis={'index', 'columns'}, ...)``\u001B[39;00m\n\u001B[1;32m   5527\u001B[0m \n\u001B[1;32m   5528\u001B[0m \u001B[38;5;124;03m    We *highly* recommend using keyword arguments to clarify your\u001B[39;00m\n\u001B[1;32m   5529\u001B[0m \u001B[38;5;124;03m    intent.\u001B[39;00m\n\u001B[1;32m   5530\u001B[0m \n\u001B[1;32m   5531\u001B[0m \u001B[38;5;124;03m    Rename columns using a mapping:\u001B[39;00m\n\u001B[1;32m   5532\u001B[0m \n\u001B[1;32m   5533\u001B[0m \u001B[38;5;124;03m    >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\u001B[39;00m\n\u001B[1;32m   5534\u001B[0m \u001B[38;5;124;03m    >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\u001B[39;00m\n\u001B[1;32m   5535\u001B[0m \u001B[38;5;124;03m       a  c\u001B[39;00m\n\u001B[1;32m   5536\u001B[0m \u001B[38;5;124;03m    0  1  4\u001B[39;00m\n\u001B[1;32m   5537\u001B[0m \u001B[38;5;124;03m    1  2  5\u001B[39;00m\n\u001B[1;32m   5538\u001B[0m \u001B[38;5;124;03m    2  3  6\u001B[39;00m\n\u001B[1;32m   5539\u001B[0m \n\u001B[1;32m   5540\u001B[0m \u001B[38;5;124;03m    Rename index using a mapping:\u001B[39;00m\n\u001B[1;32m   5541\u001B[0m \n\u001B[1;32m   5542\u001B[0m \u001B[38;5;124;03m    >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\u001B[39;00m\n\u001B[1;32m   5543\u001B[0m \u001B[38;5;124;03m       A  B\u001B[39;00m\n\u001B[1;32m   5544\u001B[0m \u001B[38;5;124;03m    x  1  4\u001B[39;00m\n\u001B[1;32m   5545\u001B[0m \u001B[38;5;124;03m    y  2  5\u001B[39;00m\n\u001B[1;32m   5546\u001B[0m \u001B[38;5;124;03m    z  3  6\u001B[39;00m\n\u001B[1;32m   5547\u001B[0m \n\u001B[1;32m   5548\u001B[0m \u001B[38;5;124;03m    Cast index labels to a different type:\u001B[39;00m\n\u001B[1;32m   5549\u001B[0m \n\u001B[1;32m   5550\u001B[0m \u001B[38;5;124;03m    >>> df.index\u001B[39;00m\n\u001B[1;32m   5551\u001B[0m \u001B[38;5;124;03m    RangeIndex(start=0, stop=3, step=1)\u001B[39;00m\n\u001B[1;32m   5552\u001B[0m \u001B[38;5;124;03m    >>> df.rename(index=str).index\u001B[39;00m\n\u001B[1;32m   5553\u001B[0m \u001B[38;5;124;03m    Index(['0', '1', '2'], dtype='object')\u001B[39;00m\n\u001B[1;32m   5554\u001B[0m \n\u001B[1;32m   5555\u001B[0m \u001B[38;5;124;03m    >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\u001B[39;00m\n\u001B[1;32m   5556\u001B[0m \u001B[38;5;124;03m    Traceback (most recent call last):\u001B[39;00m\n\u001B[1;32m   5557\u001B[0m \u001B[38;5;124;03m    KeyError: ['C'] not found in axis\u001B[39;00m\n\u001B[1;32m   5558\u001B[0m \n\u001B[1;32m   5559\u001B[0m \u001B[38;5;124;03m    Using axis-style parameters:\u001B[39;00m\n\u001B[1;32m   5560\u001B[0m \n\u001B[1;32m   5561\u001B[0m \u001B[38;5;124;03m    >>> df.rename(str.lower, axis='columns')\u001B[39;00m\n\u001B[1;32m   5562\u001B[0m \u001B[38;5;124;03m       a  b\u001B[39;00m\n\u001B[1;32m   5563\u001B[0m \u001B[38;5;124;03m    0  1  4\u001B[39;00m\n\u001B[1;32m   5564\u001B[0m \u001B[38;5;124;03m    1  2  5\u001B[39;00m\n\u001B[1;32m   5565\u001B[0m \u001B[38;5;124;03m    2  3  6\u001B[39;00m\n\u001B[1;32m   5566\u001B[0m \n\u001B[1;32m   5567\u001B[0m \u001B[38;5;124;03m    >>> df.rename({1: 2, 2: 4}, axis='index')\u001B[39;00m\n\u001B[1;32m   5568\u001B[0m \u001B[38;5;124;03m       A  B\u001B[39;00m\n\u001B[1;32m   5569\u001B[0m \u001B[38;5;124;03m    0  1  4\u001B[39;00m\n\u001B[1;32m   5570\u001B[0m \u001B[38;5;124;03m    2  2  5\u001B[39;00m\n\u001B[1;32m   5571\u001B[0m \u001B[38;5;124;03m    4  3  6\u001B[39;00m\n\u001B[1;32m   5572\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   5573\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_rename(\n\u001B[1;32m   5574\u001B[0m         mapper\u001B[38;5;241m=\u001B[39mmapper,\n\u001B[1;32m   5575\u001B[0m         index\u001B[38;5;241m=\u001B[39mindex,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5581\u001B[0m         errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m   5582\u001B[0m     )\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "\n",
    "#Descriptions sheet. Note the use of .rename to correct column names that are not correctely named in the source file\n",
    "desc = pd.read_excel('proshares_analysis_data.xlsx','descriptions').rename(columns={'Unnamed: 0':'Symbol'}).set_index('Symbol')\n",
    "\n",
    "#Hedge Fund Data\n",
    "hf = pd.read_excel('proshares_analysis_data.xlsx','hedge_fund_series').set_index('date')\n",
    "\n",
    "#Merrill Lynch Factor Data\n",
    "mf = pd.read_excel('proshares_analysis_data.xlsx','merrill_factors').set_index('date')\n",
    "\n",
    "#Other Data\n",
    "od = pd.read_excel('proshares_analysis_data.xlsx','other_data').set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61a91b",
   "metadata": {},
   "source": [
    "### 1. For the series in the “hedge fund series” tab, report the following summary statistics (annualize these statistics):\n",
    "#### (a) mean\n",
    "#### (b) volatility\n",
    "#### (c) Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_meterics_table = performanceMetrics(hf, annualization=12)\n",
    "display(performance_meterics_table.style.format\\\n",
    "        (formatter = {'Sharpe' : '{:,.2f}', 'Mean': '{:,.2%}', 'Vol': '{:,.2%}', 'Min': '{:,.2%}', 'Max': '{:,.2%}'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac6066",
   "metadata": {},
   "source": [
    "### 2. For the series in the “hedge fund series” tab, calculate the following statistics related to tail- risk (no need to annualize any of these statistics).\n",
    "#### (a) Skewness\n",
    "#### (b) Excess Kurtosis (in excess of 3)\n",
    "#### (c) VaR (.05) - the fifth quantile of historic returns\n",
    "#### (d) CVaR (.05) - the mean of the returns at or below the fifth quantile\n",
    "#### (e) Maximum drawdown - include the dates of the max/min/recovery within the max drawdown period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_metrics_table = tailMetrics(hf)\n",
    "tail_metrics_table['Kurtosis'] = tail_metrics_table['K urtosis'] - 3\n",
    "display(tail_metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce4673",
   "metadata": {},
   "source": [
    "### 3. For the series in the “hedge fund series” tab, run a regression of each against SPY (found in the “merrill factors” tab.) Include an intercept. Report the following regression-based statistics (annualize as necessary):\n",
    "#### (a) Market Beta\n",
    "#### (b) Treynor Ratio\n",
    "#### (c) Information ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ols_metrics(mf['SPY US Equity'], hf, annualization=12, ignorenan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235320f",
   "metadata": {},
   "source": [
    "### 4. Relative Performance\n",
    "Discuss the previous statistics, and what they tell us about...\n",
    "\n",
    "\n",
    "\n",
    "#### (a) the differences between SPY and the hedge-fund series?\n",
    "- Compared to SPY, all hedge fund series have negative alpha (lower mean excess return compared to SPY) and hence negative information ratio (Sharpe of the residual return)\n",
    "- All series have SPY/market beta near the 0.3-0.4 range, which means they all have a fairly low exposure to the market.\n",
    "- Given that they have some SPY beta, their total return is positive (Sharpe is positive) but when we strip this factor out, the hedged performance has a negative Sharpe ratio as seen by the Info Ratio (which is the Sharpe Ratio of the hedged position.)\n",
    "\n",
    "\n",
    "\n",
    "#### (b) which performs better between HDG and QAI.\n",
    "\n",
    "- HDG has a lower alpha and information ratio, while QAI has a lower beta. \n",
    "- However, when beta is adjusted with the beta risk (Treynor ratio), the data shows that HDG has a lower performance.\n",
    "- Overall, **QAI performs better than HDG**.\n",
    "\n",
    "\n",
    "\n",
    "#### (c) whether HDG and the ML series capture the most notable properties of HFRI.\n",
    "\n",
    "- Both HDG and the ML series fail to deliver the same high returns compensated with the high risk of HRFI. \n",
    "- The HFRI also shows a very high excess kurtosis, but all of the hedge-fund series has a very small excess kurtosis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c00974",
   "metadata": {},
   "source": [
    "### 5. Report the correlation matrix for these assets.\n",
    "#### (a) Show the correlations as a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d84d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = pd.concat([hf,mf], axis=1).corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cor_table, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e983e",
   "metadata": {},
   "source": [
    "#### (b) Which series have the highest and lowest correlations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9555584",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_table = hf.corr()\n",
    "cor_table[cor_table == 1] = None\n",
    "cor_table = cor_table.unstack().dropna()\n",
    "max_cor = cor_table.max()\n",
    "min_cor = cor_table.min()\n",
    "\n",
    "print('Strongest correlation is between: '+ str(cor_table[cor_table==max_cor].index[0]))\n",
    "print('Weakest correlation is between: '+ str(cor_table[cor_table==min_cor].index[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea8db1",
   "metadata": {},
   "source": [
    "### 6. Replicate HFRI with the six factors listed on the “merrill factors” tab. Include a constant, and run the unrestricted regression,\n",
    "$$\n",
    "\\begin{align}\n",
    "r^{hfri}_t &= \\alpha^{merr} + x^{merr}_t\\beta^{merr} + \\epsilon^{merr}_t \\\\\n",
    "\\hat{r}^{hfri}_t &\\equiv \\hat{\\alpha}^{merr} + x^{merr}_t\\hat{\\beta}^{merr}\n",
    "\\end{align}\n",
    "$$\n",
    "### Note that the second equation is just our notation for the fitted replication.\n",
    "#### (a) Report the intercept and betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0782b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_meterics = get_ols_metrics(mf, hf, annualization=12)\n",
    "names = list(mf.columns)\n",
    "names.append('alpha')\n",
    "display(ols_meterics[list(names)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a5740",
   "metadata": {},
   "source": [
    "#### (b) Are the betas realistic position sizes, or do they require huge long-short positions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f1cec",
   "metadata": {},
   "source": [
    "The betas shows large positions in USGGM3M index, sometimes it's beta is more than 10 times the beta of SPY. But that's also because USGGM3M has lower volatality, so if we standardize betas by volatality, we see that the beta are similar and so the position sizes are realistic. Below calculation supports this argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = np.array(performanceMetrics(mf)['Vol'])\n",
    "beta = np.array(ols_meterics.loc['HFRIFWI Index'][list(mf.columns)])\n",
    "beta_weights = beta*vol\n",
    "print(beta_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7681118",
   "metadata": {},
   "source": [
    "#### (c) Report the R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa914def",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(ols_meterics['r-squared']).style.format('{:,.2%}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f62f1",
   "metadata": {},
   "source": [
    "#### (d) Report the volatility of $\\epsilon^{merr}$ (the tracking error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce04ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(ols_meterics.alpha/ols_meterics['Info Ratio']).style.format('{:,.2%}'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
